{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c35b006",
   "metadata": {},
   "source": [
    "# Vehicle Tracking & Line Counting (YOLOv11 + BoT-SORT)\n",
    "\n",
    "This notebook mirrors the “real-time vehicle tracking and counting” tutorial flow, but uses **YOLOv11** with **BoT-SORT** and writes a single annotated video with **line-based counts** (no phases).\n",
    "\n",
    "**What it does:**\n",
    "- Detect vehicles (car, motorcycle, bus, truck)\n",
    "- Track them with BoT-SORT (IDs)\n",
    "- Count crossings over **three horizontal line segments** A/B/C\n",
    "- Save the result to `vehicle_lines_counted.mp4`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d2e19",
   "metadata": {},
   "source": [
    "## 0) Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f657283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ultralytics opencv-python shapely lapx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0512be",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c882273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK: yolo11m.pt vehicles.mp4\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math, cv2, time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Files ---\n",
    "WEIGHTS = 'yolo11m.pt'    # try yolo11s/m for stability, or yolo11n for speed\n",
    "SOURCE  = 'vehicles.mp4'         # same naming as many tutorials; set to your video path or 0 for webcam\n",
    "\n",
    "# --- Classes (COCO) ---\n",
    "# car=2, motorcycle=3, bus=5, truck=7\n",
    "VEHICLE_CLASSES = [2, 3, 5, 7]\n",
    "\n",
    "# --- Detection params ---\n",
    "CONF  = 0.35\n",
    "IOU   = 0.5\n",
    "IMGSZ = 960\n",
    "\n",
    "# --- Line segments (A/B/C) ---\n",
    "# Adjust these to match your video frame geometry.\n",
    "# Format: (x1, y1), (x2, y2); here: three horizontal segments near y=480\n",
    "start_line_A = (0,   480); end_line_A = (480,  480)\n",
    "start_line_B = (525, 480); end_line_B = (745,  480)\n",
    "start_line_C = (895, 480); end_line_C = (1165, 480)\n",
    "\n",
    "# Colors (BGR)\n",
    "COLOR_A = (0, 255, 0)     # green\n",
    "COLOR_B = (255, 0, 0)     # blue \n",
    "COLOR_C = (0, 0, 255)     # red\n",
    "COLOR_ID = (0, 170, 255)  # amber for boxes/IDs\n",
    "COLOR_TXT = (255, 255, 255)\n",
    "\n",
    "# Counters\n",
    "counter_A = 0\n",
    "counter_B = 0\n",
    "counter_C = 0\n",
    "\n",
    "# Trajectories: track_id -> deque of recent center points\n",
    "points = defaultdict(lambda: deque(maxlen=32))\n",
    "\n",
    "print('Config OK:', WEIGHTS, SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ed823",
   "metadata": {},
   "source": [
    "## 2) Run — Detect + Track + Line Counting → `vehicle_lines_counted.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee06f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: vehicle_lines_counted.mp4 (2112 frames)\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = YOLO(WEIGHTS)\n",
    "\n",
    "# Start tracking stream (use BoT-SORT by default; you can switch to 'deepsort.yaml')\n",
    "results = model.track(\n",
    "    source=SOURCE,\n",
    "    tracker='botsort.yaml',         # or 'deepsort.yaml'\n",
    "    stream=True,\n",
    "    classes=VEHICLE_CLASSES,        # keep vehicle classes only\n",
    "    conf=CONF,\n",
    "    iou=IOU,\n",
    "    imgsz=IMGSZ,\n",
    "    persist=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "writer = None\n",
    "frames = 0\n",
    "\n",
    "global counter_A, counter_B, counter_C\n",
    "\n",
    "# Map COCO class IDs to nice names\n",
    "NAME_MAP = {2: \"Car\", 3: \"Motorcycle\", 5: \"Bus\", 7: \"Truck\"}\n",
    "\n",
    "for r in results:\n",
    "    # Base frame\n",
    "    frame = r.orig_img.copy()\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Draw line segments A/B/C (thick for visibility)\n",
    "    cv2.line(frame, start_line_A, end_line_A, COLOR_A, 12)\n",
    "    cv2.line(frame, start_line_B, end_line_B, COLOR_B, 12)\n",
    "    cv2.line(frame, start_line_C, end_line_C, COLOR_C, 12)\n",
    "\n",
    "    # Semi-transparent blend (like tutorial)\n",
    "    frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)\n",
    "\n",
    "    # Lazy-init writer on first frame\n",
    "    if writer is None:\n",
    "        h, w = frame.shape[:2]\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter('vehicle_lines_counted.mp4', fourcc, 30.0, (w, h))\n",
    "\n",
    "    # Collect tracked vehicle boxes + IDs\n",
    "    current_ids = []\n",
    "    if r.boxes is not None and len(r.boxes) > 0 and getattr(r.boxes, 'id', None) is not None:\n",
    "        ids = r.boxes.id.int().cpu().numpy()\n",
    "        cls = r.boxes.cls.int().cpu().numpy()\n",
    "        # mask to allowed vehicles\n",
    "        keep = np.isin(cls, np.array(VEHICLE_CLASSES))\n",
    "        xyxy = r.boxes.xyxy.cpu().numpy()[keep]\n",
    "        ids_f = ids[keep]\n",
    "        cls_f = cls[keep]  # <-- aligned class IDs for kept detections\n",
    "\n",
    "        # draw and update points\n",
    "        for (x1, y1, x2, y2), tid, cid in zip(xyxy, ids_f, cls_f):\n",
    "            tid = int(tid)\n",
    "            class_name = NAME_MAP.get(int(cid), str(int(cid)))  # fallback to numeric if unmapped\n",
    "\n",
    "            # draw box + \"<id> <Class>\" label (e.g., \"1 Car\")\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), COLOR_ID, 3)\n",
    "            pos = (int(x1), max(0, int(y1) - 5))  # ensure a proper (x, y) tuple of ints\n",
    "            cv2.putText(frame, f\"{tid} {class_name}\",\n",
    "                        pos,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_ID, 2)\n",
    "\n",
    "            # center point\n",
    "            cx, cy = int((x1 + x2) / 2), int((y1) + (y2 - y1) / 2)\n",
    "            points[tid].append((cx, cy))\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 255, 0), -1)\n",
    "\n",
    "            # draw small trajectory\n",
    "            pt_list = points[tid]\n",
    "            for i in range(1, len(pt_list)):\n",
    "                p1 = pt_list[i - 1]; p2 = pt_list[i]\n",
    "                if p1 is None or p2 is None: continue\n",
    "                cv2.line(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # crossing logic \n",
    "            # get earliest stored point (oldest) as \"last_point\" along the path\n",
    "            if len(points[tid]) >= 2:\n",
    "                last_point_x = points[tid][0][0]\n",
    "                last_point_y = points[tid][0][1]\n",
    "\n",
    "                # A segment\n",
    "                if cy > start_line_A[1] and start_line_A[0] < cx < end_line_A[0] and last_point_y < start_line_A[1]:\n",
    "                    counter_A += 1\n",
    "                    points[tid].clear()  # reset path to avoid double-counts\n",
    "\n",
    "                # B segment\n",
    "                elif cy > start_line_B[1] and start_line_B[0] < cx < end_line_B[0] and last_point_y < start_line_B[1]:\n",
    "                    counter_B += 1\n",
    "                    points[tid].clear()\n",
    "\n",
    "                # C segment\n",
    "                elif cy > start_line_C[1] and start_line_C[0] < cx < end_line_C[0] and last_point_y < start_line_C[1]:\n",
    "                    counter_C += 1\n",
    "                    points[tid].clear()\n",
    "\n",
    "    # HUD: show current counts and labels for A/B/C\n",
    "    cv2.putText(frame, \"A\", (10, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "    cv2.putText(frame, \"B\", (530, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "    cv2.putText(frame, \"C\", (910, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "    cv2.putText(frame, f\"{counter_A}\", (270, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "    cv2.putText(frame, f\"{counter_B}\", (620, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "    cv2.putText(frame, f\"{counter_C}\", (1040, 483), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR_TXT, 2)\n",
    "\n",
    "    # Write frame\n",
    "    writer.write(frame)\n",
    "    frames += 1\n",
    "\n",
    "# Cleanup\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "\n",
    "print(f\"Saved: vehicle_lines_counted.mp4 ({frames} frames)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
